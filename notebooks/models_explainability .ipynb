{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb1f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dee4c8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING MULTI-MODEL CONGRESSIONAL POLARIZATION ANALYSIS\n",
      "================================================================================\n",
      "Loading pickle files for all models...\n",
      "âœ“ Loaded SVM data\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cupy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 335\u001b[39m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pipeline, analysis\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     pipeline, analysis = main()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 324\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    321\u001b[39m pipeline = MultiModelPolarizationAnalysisPipeline()\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# Run analysis for specific congress (e.g., 76) or all available\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m analysis = pipeline.run_multi_model_analysis(congress_nums=[\u001b[32m76\u001b[39m], top_n=\u001b[32m10\u001b[39m)\n\u001b[32m    326\u001b[39m \u001b[38;5;66;03m# You can also run for multiple congresses:\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[38;5;66;03m# analysis = pipeline.run_multi_model_analysis(congress_nums=[76, 77, 78], top_n=10)\u001b[39;00m\n\u001b[32m    328\u001b[39m \n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# Or for all available congresses:\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# analysis = pipeline.run_multi_model_analysis(top_n=10)\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline, analysis\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 298\u001b[39m, in \u001b[36mMultiModelPolarizationAnalysisPipeline.run_multi_model_analysis\u001b[39m\u001b[34m(self, congress_nums, top_n)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m    297\u001b[39m \u001b[38;5;66;03m# Load and aggregate data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m \u001b[38;5;28mself\u001b[39m.load_all_pickles()\n\u001b[32m    299\u001b[39m \u001b[38;5;28mself\u001b[39m.aggregate_all_models()\n\u001b[32m    300\u001b[39m \u001b[38;5;28mself\u001b[39m.analyze_partisan_distinctions_all_models(top_n=\u001b[32m20\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mMultiModelPolarizationAnalysisPipeline.load_all_pickles\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(pickle_path, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m         \u001b[38;5;28mself\u001b[39m.raw_data[model] = pickle.load(f)\n\u001b[32m     30\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ“ Loaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m data\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cupy'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "class MultiModelPolarizationAnalysisPipeline:\n",
    "    def __init__(self, base_path=\"../feature_importance/congress_feature_importance_bigram_100_min_df\"):\n",
    "        self.base_path = base_path\n",
    "        self.models = ['svm', 'lr', 'bayes']\n",
    "        self.model_names = {\n",
    "            'svm': 'Support Vector Machine',\n",
    "            'lr': 'Logistic Regression', \n",
    "            'bayes': 'Complement Naive Bayes'\n",
    "        }\n",
    "        \n",
    "        # Store data for each model\n",
    "        self.raw_data = {}\n",
    "        self.aggregated_data = {}\n",
    "        self.polarization_analysis = {}\n",
    "    \n",
    "    def load_all_pickles(self):\n",
    "        \"\"\"Load pickle files for all three models\"\"\"\n",
    "        print(\"Loading pickle files for all models...\")\n",
    "        \n",
    "        for model in self.models:\n",
    "            pickle_path = f\"{self.base_path}_{model}.pkl\"\n",
    "            try:\n",
    "                with open(pickle_path, 'rb') as f:\n",
    "                    self.raw_data[model] = pickle.load(f)\n",
    "                print(f\"âœ“ Loaded {model.upper()} data\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"âœ— Could not find {pickle_path}\")\n",
    "                continue\n",
    "        \n",
    "        # Get congress numbers and seeds from first available model\n",
    "        if self.raw_data:\n",
    "            first_model_data = list(self.raw_data.values())[0]\n",
    "            congress_nums = set()\n",
    "            seeds = set()\n",
    "            for key in first_model_data.keys():\n",
    "                congress_num, seed = key.split('_')\n",
    "                congress_nums.add(int(congress_num))\n",
    "                seeds.add(int(seed))\n",
    "            \n",
    "            print(f\"Data covers {len(congress_nums)} congress sessions: {sorted(congress_nums)}\")\n",
    "            print(f\"Using {len(seeds)} seeds: {sorted(seeds)}\")\n",
    "        \n",
    "        return self.raw_data\n",
    "    \n",
    "    def aggregate_all_models(self):\n",
    "        \"\"\"Aggregate terms for all models\"\"\"\n",
    "        print(\"Aggregating coefficients across seeds for all models...\")\n",
    "        \n",
    "        for model in self.models:\n",
    "            if model not in self.raw_data:\n",
    "                continue\n",
    "                \n",
    "            congress_term_coefficients = defaultdict(lambda: defaultdict(list))\n",
    "            \n",
    "            for key, term_coeffs in self.raw_data[model].items():\n",
    "                congress_num, seed = key.split('_')\n",
    "                congress_num = int(congress_num)\n",
    "                \n",
    "                for term, coefficient in term_coeffs.items():\n",
    "                    congress_term_coefficients[congress_num][term].append(coefficient)\n",
    "            \n",
    "            # Calculate aggregated statistics\n",
    "            self.aggregated_data[model] = {}\n",
    "            for congress_num, terms_dict in congress_term_coefficients.items():\n",
    "                self.aggregated_data[model][congress_num] = {}\n",
    "                \n",
    "                for term, coeff_list in terms_dict.items():\n",
    "                    mean_coeff = np.mean(coeff_list)\n",
    "                    self.aggregated_data[model][congress_num][term] = {\n",
    "                        'mean_coefficient': mean_coeff,\n",
    "                        'abs_coefficient': abs(mean_coeff),\n",
    "                        'std_coefficient': np.std(coeff_list),\n",
    "                        'n_seeds': len(coeff_list)\n",
    "                    }\n",
    "        \n",
    "        return self.aggregated_data\n",
    "    \n",
    "    def analyze_partisan_distinctions_all_models(self, top_n=20):\n",
    "        \"\"\"Analyze partisan distinctions for all models\"\"\"\n",
    "        print(f\"\\nAnalyzing top {top_n} partisan distinguishing terms for all models...\")\n",
    "        \n",
    "        for model in self.models:\n",
    "            if model not in self.aggregated_data:\n",
    "                continue\n",
    "                \n",
    "            self.polarization_analysis[model] = {}\n",
    "            \n",
    "            for congress_num, terms_data in self.aggregated_data[model].items():\n",
    "                # Sort ALL terms by absolute coefficient\n",
    "                sorted_terms = sorted(terms_data.items(), \n",
    "                                    key=lambda x: x[1]['abs_coefficient'], \n",
    "                                    reverse=True)\n",
    "                \n",
    "                republican_terms = []\n",
    "                democrat_terms = []\n",
    "                \n",
    "                for term, data in sorted_terms:\n",
    "                    if data['mean_coefficient'] > 0 and len(republican_terms) < top_n:\n",
    "                        republican_terms.append({\n",
    "                            'term': term,\n",
    "                            'coefficient': data['mean_coefficient'],\n",
    "                            'abs_coefficient': data['abs_coefficient'],\n",
    "                            'std': data['std_coefficient']\n",
    "                        })\n",
    "                    elif data['mean_coefficient'] < 0 and len(democrat_terms) < top_n:\n",
    "                        democrat_terms.append({\n",
    "                            'term': term,\n",
    "                            'coefficient': data['mean_coefficient'],\n",
    "                            'abs_coefficient': data['abs_coefficient'],\n",
    "                            'std': data['std_coefficient']\n",
    "                        })\n",
    "                    \n",
    "                    if len(republican_terms) >= top_n and len(democrat_terms) >= top_n:\n",
    "                        break\n",
    "                \n",
    "                self.polarization_analysis[model][congress_num] = {\n",
    "                    'republican_terms': republican_terms,\n",
    "                    'democrat_terms': democrat_terms\n",
    "                }\n",
    "        \n",
    "        return self.polarization_analysis\n",
    "    \n",
    "    def print_multi_model_comparison(self, congress_num, top_n=10):\n",
    "        \"\"\"Print comparison across all models for a specific congress\"\"\"\n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(f\"MULTI-MODEL PARTISAN LANGUAGE COMPARISON - CONGRESS {congress_num}\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        # Check if congress exists in all models\n",
    "        available_models = []\n",
    "        for model in self.models:\n",
    "            if model in self.polarization_analysis and congress_num in self.polarization_analysis[model]:\n",
    "                available_models.append(model)\n",
    "        \n",
    "        if not available_models:\n",
    "            print(f\"No data available for Congress {congress_num}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Available models: {', '.join([self.model_names[m] for m in available_models])}\")\n",
    "        \n",
    "        # Republican terms comparison\n",
    "        print(f\"\\nðŸ”´ TOP {top_n} REPUBLICAN-DISTINGUISHING TERMS:\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for model in available_models:\n",
    "            data = self.polarization_analysis[model][congress_num]\n",
    "            print(f\"\\n{self.model_names[model].upper()}:\")\n",
    "            for i, term_data in enumerate(data['republican_terms'][:top_n], 1):\n",
    "                print(f\"  {i:2d}. {term_data['term']:<20} (coeff: {term_data['coefficient']:+.3f})\")\n",
    "        \n",
    "        # Democrat terms comparison\n",
    "        print(f\"\\nðŸ”µ TOP {top_n} DEMOCRAT-DISTINGUISHING TERMS:\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for model in available_models:\n",
    "            data = self.polarization_analysis[model][congress_num]\n",
    "            print(f\"\\n{self.model_names[model].upper()}:\")\n",
    "            for i, term_data in enumerate(data['democrat_terms'][:top_n], 1):\n",
    "                print(f\"  {i:2d}. {term_data['term']:<20} (coeff: {term_data['coefficient']:+.3f})\")\n",
    "    \n",
    "    def analyze_model_agreement(self, congress_num, top_n=10):\n",
    "        \"\"\"Analyze agreement between models for specific congress\"\"\"\n",
    "        print(f\"\\nðŸ“Š MODEL AGREEMENT ANALYSIS - CONGRESS {congress_num}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        available_models = []\n",
    "        for model in self.models:\n",
    "            if model in self.polarization_analysis and congress_num in self.polarization_analysis[model]:\n",
    "                available_models.append(model)\n",
    "        \n",
    "        if len(available_models) < 2:\n",
    "            print(\"Need at least 2 models for agreement analysis\")\n",
    "            return\n",
    "        \n",
    "        # Get top terms for each model\n",
    "        republican_terms_by_model = {}\n",
    "        democrat_terms_by_model = {}\n",
    "        \n",
    "        for model in available_models:\n",
    "            data = self.polarization_analysis[model][congress_num]\n",
    "            republican_terms_by_model[model] = set([t['term'] for t in data['republican_terms'][:top_n]])\n",
    "            democrat_terms_by_model[model] = set([t['term'] for t in data['democrat_terms'][:top_n]])\n",
    "        \n",
    "        # Find common terms\n",
    "        print(\"\\nREPUBLICAN TERMS AGREEMENT:\")\n",
    "        all_rep_terms = set.intersection(*republican_terms_by_model.values())\n",
    "        print(f\"Terms agreed upon by ALL models ({len(all_rep_terms)}): {', '.join(sorted(all_rep_terms)) if all_rep_terms else 'None'}\")\n",
    "        \n",
    "        # Pairwise agreements\n",
    "        for i, model1 in enumerate(available_models):\n",
    "            for model2 in available_models[i+1:]:\n",
    "                overlap = republican_terms_by_model[model1] & republican_terms_by_model[model2]\n",
    "                overlap_pct = len(overlap) / top_n * 100\n",
    "                print(f\"{model1.upper()} vs {model2.upper()}: {len(overlap)}/{top_n} terms ({overlap_pct:.1f}% agreement)\")\n",
    "        \n",
    "        print(\"\\nDEMOCRAT TERMS AGREEMENT:\")\n",
    "        all_dem_terms = set.intersection(*democrat_terms_by_model.values())\n",
    "        print(f\"Terms agreed upon by ALL models ({len(all_dem_terms)}): {', '.join(sorted(all_dem_terms)) if all_dem_terms else 'None'}\")\n",
    "        \n",
    "        for i, model1 in enumerate(available_models):\n",
    "            for model2 in available_models[i+1:]:\n",
    "                overlap = democrat_terms_by_model[model1] & democrat_terms_by_model[model2]\n",
    "                overlap_pct = len(overlap) / top_n * 100\n",
    "                print(f\"{model1.upper()} vs {model2.upper()}: {len(overlap)}/{top_n} terms ({overlap_pct:.1f}% agreement)\")\n",
    "    \n",
    "    def create_consensus_ranking(self, congress_num, top_n=10):\n",
    "        \"\"\"Create consensus ranking based on all models\"\"\"\n",
    "        print(f\"\\nðŸ† CONSENSUS RANKING - CONGRESS {congress_num}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        available_models = []\n",
    "        for model in self.models:\n",
    "            if model in self.polarization_analysis and congress_num in self.polarization_analysis[model]:\n",
    "                available_models.append(model)\n",
    "        \n",
    "        if len(available_models) < 2:\n",
    "            print(\"Need at least 2 models for consensus ranking\")\n",
    "            return\n",
    "        \n",
    "        # Collect all terms with their rankings across models\n",
    "        term_rankings = defaultdict(lambda: {'republican_ranks': [], 'democrat_ranks': [], 'republican_coeffs': [], 'democrat_coeffs': []})\n",
    "        \n",
    "        for model in available_models:\n",
    "            data = self.polarization_analysis[model][congress_num]\n",
    "            \n",
    "            # Republican terms\n",
    "            for rank, term_data in enumerate(data['republican_terms'][:top_n], 1):\n",
    "                term = term_data['term']\n",
    "                term_rankings[term]['republican_ranks'].append(rank)\n",
    "                term_rankings[term]['republican_coeffs'].append(term_data['coefficient'])\n",
    "            \n",
    "            # Democrat terms  \n",
    "            for rank, term_data in enumerate(data['democrat_terms'][:top_n], 1):\n",
    "                term = term_data['term']\n",
    "                term_rankings[term]['democrat_ranks'].append(rank)\n",
    "                term_rankings[term]['democrat_coeffs'].append(term_data['coefficient'])\n",
    "        \n",
    "        # Calculate consensus scores for Republican terms\n",
    "        republican_consensus = []\n",
    "        for term, rankings in term_rankings.items():\n",
    "            if rankings['republican_ranks']:\n",
    "                avg_rank = np.mean(rankings['republican_ranks'])\n",
    "                avg_coeff = np.mean(rankings['republican_coeffs'])\n",
    "                n_models = len(rankings['republican_ranks'])\n",
    "                # Consensus score: lower average rank is better, weight by number of models\n",
    "                consensus_score = (top_n + 1 - avg_rank) * n_models\n",
    "                republican_consensus.append({\n",
    "                    'term': term,\n",
    "                    'avg_rank': avg_rank,\n",
    "                    'avg_coeff': avg_coeff,\n",
    "                    'n_models': n_models,\n",
    "                    'consensus_score': consensus_score\n",
    "                })\n",
    "        \n",
    "        # Calculate consensus scores for Democrat terms\n",
    "        democrat_consensus = []\n",
    "        for term, rankings in term_rankings.items():\n",
    "            if rankings['democrat_ranks']:\n",
    "                avg_rank = np.mean(rankings['democrat_ranks'])\n",
    "                avg_coeff = np.mean(rankings['democrat_coeffs'])\n",
    "                n_models = len(rankings['democrat_ranks'])\n",
    "                consensus_score = (top_n + 1 - avg_rank) * n_models\n",
    "                democrat_consensus.append({\n",
    "                    'term': term,\n",
    "                    'avg_rank': avg_rank,\n",
    "                    'avg_coeff': avg_coeff,\n",
    "                    'n_models': n_models,\n",
    "                    'consensus_score': consensus_score\n",
    "                })\n",
    "        \n",
    "        # Sort by consensus score\n",
    "        republican_consensus.sort(key=lambda x: x['consensus_score'], reverse=True)\n",
    "        democrat_consensus.sort(key=lambda x: x['consensus_score'], reverse=True)\n",
    "        \n",
    "        print(f\"\\nTOP CONSENSUS REPUBLICAN TERMS:\")\n",
    "        for i, term_data in enumerate(republican_consensus[:top_n], 1):\n",
    "            print(f\"  {i:2d}. {term_data['term']:<20} (avg_coeff: {term_data['avg_coeff']:+.3f}, \"\n",
    "                  f\"avg_rank: {term_data['avg_rank']:.1f}, models: {term_data['n_models']}/{len(available_models)})\")\n",
    "        \n",
    "        print(f\"\\nTOP CONSENSUS DEMOCRAT TERMS:\")\n",
    "        for i, term_data in enumerate(democrat_consensus[:top_n], 1):\n",
    "            print(f\"  {i:2d}. {term_data['term']:<20} (avg_coeff: {term_data['avg_coeff']:+.3f}, \"\n",
    "                  f\"avg_rank: {term_data['avg_rank']:.1f}, models: {term_data['n_models']}/{len(available_models)})\")\n",
    "        \n",
    "        return republican_consensus, democrat_consensus\n",
    "    \n",
    "    def run_multi_model_analysis(self, congress_nums=None, top_n=10):\n",
    "        \"\"\"Run complete multi-model analysis\"\"\"\n",
    "        print(\"RUNNING MULTI-MODEL CONGRESSIONAL POLARIZATION ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Load and aggregate data\n",
    "        self.load_all_pickles()\n",
    "        self.aggregate_all_models()\n",
    "        self.analyze_partisan_distinctions_all_models(top_n=20)\n",
    "        \n",
    "        # Get available congress numbers\n",
    "        if congress_nums is None:\n",
    "            available_congress = set()\n",
    "            for model_data in self.polarization_analysis.values():\n",
    "                available_congress.update(model_data.keys())\n",
    "            congress_nums = sorted(list(available_congress))\n",
    "        \n",
    "        # Run analysis for each congress\n",
    "        for congress_num in congress_nums:\n",
    "            self.print_multi_model_comparison(congress_num, top_n)\n",
    "            self.analyze_model_agreement(congress_num, top_n)\n",
    "            self.create_consensus_ranking(congress_num, top_n)\n",
    "            print(\"\\n\" + \"=\"*100 + \"\\n\")\n",
    "        \n",
    "        return self.polarization_analysis\n",
    "\n",
    "# Usage example\n",
    "def main():\n",
    "    # Initialize pipeline\n",
    "    pipeline = MultiModelPolarizationAnalysisPipeline()\n",
    "    \n",
    "    # Run analysis for specific congress (e.g., 76) or all available\n",
    "    analysis = pipeline.run_multi_model_analysis(congress_nums=[76], top_n=10)\n",
    "    \n",
    "    # You can also run for multiple congresses:\n",
    "    # analysis = pipeline.run_multi_model_analysis(congress_nums=[76, 77, 78], top_n=10)\n",
    "    \n",
    "    # Or for all available congresses:\n",
    "    # analysis = pipeline.run_multi_model_analysis(top_n=10)\n",
    "    \n",
    "    return pipeline, analysis\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pipeline, analysis = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_polarization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
